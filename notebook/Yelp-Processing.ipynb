{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D-Cube v.s. M-Zoom on Amazon Dataset\n",
    "In the following part of notebook, we will apply the D-Cube algorithm on Amazon dataset, then compare the results with D-Cube's main compatitor - M-Zoom algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Size of the Amazon review dataset is as follows:\n",
      "Unique Users:\t\t1029432\n",
      "Unique Businesses:\t144072\n",
      "Unique Dates:\t\t4221\n"
     ]
    }
   ],
   "source": [
    "data_raw = []\n",
    "i = 0\n",
    "with open('Yelp-data/yelp_academic_dataset_review.json') as f:\n",
    "    for line in f:\n",
    "        data_raw.append(json.loads(line))\n",
    "\n",
    "user_set = []\n",
    "business_set = []\n",
    "date_set = []\n",
    "rating_set = []\n",
    "for i in range (0, len(data_raw)):\n",
    "    user_set.append(data_raw[i]['user_id'])\n",
    "    business_set.append(data_raw[i]['business_id'])\n",
    "    date_set.append(data_raw[i]['date'])\n",
    "    \n",
    "user_set = list(set(user_set))\n",
    "business_set = list(set(business_set))\n",
    "date_set = list(set(date_set))\n",
    "\n",
    "print \"The Size of the Amazon review dataset is as follows:\"\n",
    "print \"Unique Users:\\t\\t\" + str(len(user_set))\n",
    "print \"Unique Businesses:\\t\" + str(len(business_set))\n",
    "print \"Unique Dates:\\t\\t\" + str(len(date_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = dict(zip(user_set,np.arange(0,len(user_set))))\n",
    "business = dict(zip(business_set,np.arange(0,len(business_set))))\n",
    "date = dict(zip(date_set,np.arange(0,len(date_set))))\n",
    "\n",
    "real_review = []\n",
    "for i in range (0, len(data_raw)):\n",
    "    real_review.append([user[data_raw[i]['user_id']], business[data_raw[i]['business_id']], date[data_raw[i]['date']], data_raw[i]['stars']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fake Review Generator\n",
    "After getting the original Amazon review dataset, we would like to inject some fake reviews and test if both D-Cube and M-Zoom algorithm will find these fake reviews (users, business and data) or not. Now, we consider the following four different type of injective data to challenge both algorithm. \n",
    "\n",
    "### Type 1. Fraud Users (Fake users are generated to review businesses)\n",
    "In this type of injective dataset, we will generated some fraud users, who only give fake (positive and negative) reviews to some businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1 Positive Fake Reveiw Size: \n",
      "50 * 50 * 20\n",
      "Type 1 Negative Fake Reveiw Size: \n",
      "50 * 50 * 20\n"
     ]
    }
   ],
   "source": [
    "fake_user_positive = np.arange(len(user_set),len(user_set) + 50)\n",
    "fake_business_positive = np.arange(len(business_set))[np.random.permutation(len(business_set))[:50]]\n",
    "fake_date_positive = np.arange(len(date_set))[np.random.permutation(len(date_set))[:20]]\n",
    "\n",
    "fake_user_negative = np.arange(len(user_set) + 50,len(user_set) + 100)\n",
    "fake_business_negative = np.arange(len(business_set))[np.random.permutation(len(business_set))[:50]]\n",
    "fake_date_negative = np.arange(len(date_set))[np.random.permutation(len(date_set))[:20]]\n",
    "\n",
    "print \"Type 1 Positive Fake Reveiw Size: \"\n",
    "print str(len(fake_user_positive)) + \" * \" + str(len(fake_business_positive)) + \" * \" + str(len(fake_date_positive))\n",
    "\n",
    "print \"Type 1 Negative Fake Reveiw Size: \"\n",
    "print str(len(fake_user_negative)) + \" * \" + str(len(fake_business_negative)) + \" * \" + str(len(fake_date_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After injecting Type 1 fake reviews, here is the dataset we currently have:\n",
      "Size of all reviews:\t4253150\n",
      "Size of real reviews:\t4153150\n",
      "Size of fake reviews:\t100000\n"
     ]
    }
   ],
   "source": [
    "fake_review = []\n",
    "for i in range (0,len(fake_user_positive)):\n",
    "    for j in range (0,len(fake_business_positive)):\n",
    "        for k in range (0,len(fake_date_positive)):\n",
    "            fake_review.append([fake_user_positive[i],fake_business_positive[j],fake_date_positive[k],5])\n",
    "\n",
    "for i in range (0,len(fake_user_negative)):\n",
    "    for j in range (0,len(fake_business_negative)):\n",
    "        for k in range (0,len(fake_date_negative)):\n",
    "            fake_review.append([fake_user_negative[i],fake_business_negative[j],fake_date_negative[k],1])\n",
    "\n",
    "all_review = real_review + fake_review\n",
    "\n",
    "print \"After injecting Type 1 fake reviews, here is the dataset we currently have:\"\n",
    "print \"Size of all reviews:\\t\" + str(len(all_review))\n",
    "print \"Size of real reviews:\\t\" + str(len(real_review))\n",
    "print \"Size of fake reviews:\\t\" + str(len(fake_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the tensor\n",
    "After injecting the fake reviews, we would like to shuffle the whole tensor, to make sure the fake reviews are randomly distributed anywhere inside of tensor. In another word, after shuffling the tensor, the dense block detection algorithms should work really hard and carefully re-organize the order of each dimesion to return the dense blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(all_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('yelp_reviews_with_fake_1.txt','a') as f:\n",
    "    for i in range (0, len(all_review)):\n",
    "        f.write(str(all_review[i][0]) + ',' + str(all_review[i][1]) + ',' + str(all_review[i][2]) + ',' + str(all_review[i][3]) + ',' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 1 Fake Review Result:\n",
    "<img src=\"01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 2: Employed Users (Real users are employed to review businesses)\n",
    "Now, we are planning to add more challege on these two algorithms. In the Type 2 injective dataset, we are using real users, instead of generated fraud users, who will be employed to give fake (both positive and negative) reviews to some businesses. We will also do the shuffling processes after injecting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 2 Positive Fake Reveiw Size: \n",
      "50 * 50 * 20\n",
      "Type 2 Negative Fake Reveiw Size: \n",
      "50 * 50 * 20\n"
     ]
    }
   ],
   "source": [
    "fake_user_positive = np.arange(len(user_set))[np.random.permutation(len(user_set))[:50]]\n",
    "fake_business_positive = np.arange(len(business_set))[np.random.permutation(len(business_set))[:50]]\n",
    "fake_date_positive = np.arange(len(date_set))[np.random.permutation(len(date_set))[:20]]\n",
    "\n",
    "fake_user_negative = np.arange(len(user_set))[np.random.permutation(len(user_set))[:50]]\n",
    "fake_business_negative = np.arange(len(business_set))[np.random.permutation(len(business_set))[:50]]\n",
    "fake_date_negative = np.arange(len(date_set))[np.random.permutation(len(date_set))[:20]]\n",
    "\n",
    "print \"Type 2 Positive Fake Reveiw Size: \"\n",
    "print str(len(fake_user_positive)) + \" * \" + str(len(fake_business_positive)) + \" * \" + str(len(fake_date_positive))\n",
    "\n",
    "print \"Type 2 Negative Fake Reveiw Size: \"\n",
    "print str(len(fake_user_negative)) + \" * \" + str(len(fake_business_negative)) + \" * \" + str(len(fake_date_negative))\n",
    "\n",
    "fake_review = []\n",
    "for i in range (0,len(fake_user_positive)):\n",
    "    for j in range (0,len(fake_business_positive)):\n",
    "        for k in range (0,len(fake_date_positive)):\n",
    "            fake_review.append([fake_user_positive[i],fake_business_positive[j],fake_date_positive[k],5])\n",
    "\n",
    "for i in range (0,len(fake_user_negative)):\n",
    "    for j in range (0,len(fake_business_negative)):\n",
    "        for k in range (0,len(fake_date_negative)):\n",
    "            fake_review.append([fake_user_negative[i],fake_business_negative[j],fake_date_negative[k],1])\n",
    "\n",
    "all_review = real_review + fake_review\n",
    "\n",
    "with open('yelp_reviews_with_fake_2.txt','a') as f:\n",
    "    for i in range (0, len(all_review)):\n",
    "        f.write(str(all_review[i][0]) + ',' + str(all_review[i][1]) + ',' + str(all_review[i][2]) + ',' + str(all_review[i][3]) + ',' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 2 Fake Review Result:\n",
    "<img src=\"02.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 3: Employed Users (Real users are employed to review businesses)\n",
    "\n",
    "Based on the Type 2 injective data, we make the Type 3 data which randomly deleting some (30%) fake injective reviews and make the injective block be more real. In the real world, suppose some of real users or reviews are detected and blocked by Yelp, the fake reviews block could not perfectly exist.\n",
    "\n",
    "<img src=\"3.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 3 Positive Fake Reveiw Size: \n",
      "200 * 10 * 10\n",
      "Type 3 Negative Fake Reveiw Size: \n",
      "200 * 10 * 10\n"
     ]
    }
   ],
   "source": [
    "fake_user_positive = np.arange(len(user_set))[np.random.permutation(len(user_set))[:200]]\n",
    "fake_business_positive = np.arange(len(business_set))[np.random.permutation(len(business_set))[:10]]\n",
    "fake_date_positive = np.arange(len(date_set))[np.random.permutation(len(date_set))[:10]]\n",
    "\n",
    "fake_user_negative = np.arange(len(user_set))[np.random.permutation(len(user_set))[:200]]\n",
    "fake_business_negative = np.arange(len(business_set))[np.random.permutation(len(business_set))[:10]]\n",
    "fake_date_negative = np.arange(len(date_set))[np.random.permutation(len(date_set))[:10]]\n",
    "\n",
    "print \"Type 3 Positive Fake Reveiw Size: \"\n",
    "print str(len(fake_user_positive)) + \" * \" + str(len(fake_business_positive)) + \" * \" + str(len(fake_date_positive))\n",
    "\n",
    "print \"Type 3 Negative Fake Reveiw Size: \"\n",
    "print str(len(fake_user_negative)) + \" * \" + str(len(fake_business_negative)) + \" * \" + str(len(fake_date_negative))\n",
    "\n",
    "fake_review = []\n",
    "for i in range (0,len(fake_user_positive)):\n",
    "    for j in range (0,len(fake_business_positive)):\n",
    "        for k in range (0,len(fake_date_positive)):\n",
    "            fake_review.append([fake_user_positive[i],fake_business_positive[j],fake_date_positive[k],5])\n",
    "\n",
    "for i in range (0,len(fake_user_negative)):\n",
    "    for j in range (0,len(fake_business_negative)):\n",
    "        for k in range (0,len(fake_date_negative)):\n",
    "            fake_review.append([fake_user_negative[i],fake_business_negative[j],fake_date_negative[k],1])\n",
    "\n",
    "a = np.array(fake_review)\n",
    "fake_review = list(a[np.random.permutation(a.shape[0])[:int(a.shape[0]*0.7)]])\n",
    "            \n",
    "all_review = real_review + fake_review\n",
    "\n",
    "with open('yelp_reviews_with_fake_3.txt','a') as f:\n",
    "    for i in range (0, len(all_review)):\n",
    "        f.write(str(all_review[i][0]) + ',' + str(all_review[i][1]) + ',' + str(all_review[i][2]) + ',' + str(all_review[i][3]) + ',' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 3 Fake Review Result:\n",
    "<img src=\"03.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 4: Smarter Employed Users (Real users are employed to give 4 or 5 for positive reviews, and 1 or 2 for negative reviews)\n",
    "Rely on the Type 3 injective dateset, we plan to add more challenge here. In the real world, fraud users not only give 5 stars for positive reviews. but they also give 4 stars to make the fake reviews with more reality. Based on this case, we change our injective fake reviews with both 4 or 5 stars for positive reviews, and both 1 or 2 stars for negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 4 Positive Fake Reveiw Size: \n",
      "50 * 50 * 20\n",
      "Type 4 Negative Fake Reveiw Size: \n",
      "50 * 50 * 20\n"
     ]
    }
   ],
   "source": [
    "fake_user_positive = np.arange(len(user_set))[np.random.permutation(len(user_set))[:50]]\n",
    "fake_business_positive = np.arange(len(business_set))[np.random.permutation(len(business_set))[:50]]\n",
    "fake_date_positive = np.arange(len(date_set))[np.random.permutation(len(date_set))[:20]]\n",
    "\n",
    "fake_user_negative = np.arange(len(user_set))[np.random.permutation(len(user_set))[:50]]\n",
    "fake_business_negative = np.arange(len(business_set))[np.random.permutation(len(business_set))[:50]]\n",
    "fake_date_negative = np.arange(len(date_set))[np.random.permutation(len(date_set))[:20]]\n",
    "\n",
    "print \"Type 4 Positive Fake Reveiw Size: \"\n",
    "print str(len(fake_user_positive)) + \" * \" + str(len(fake_business_positive)) + \" * \" + str(len(fake_date_positive))\n",
    "\n",
    "print \"Type 4 Negative Fake Reveiw Size: \"\n",
    "print str(len(fake_user_negative)) + \" * \" + str(len(fake_business_negative)) + \" * \" + str(len(fake_date_negative))\n",
    "\n",
    "fake_review = []\n",
    "for i in range (0,len(fake_user_positive)):\n",
    "    for j in range (0,len(fake_business_positive)):\n",
    "        for k in range (0,len(fake_date_positive)):\n",
    "            fake_review.append([fake_user_positive[i],fake_business_positive[j],fake_date_positive[k],np.random.permutation([4,5])[0]])\n",
    "\n",
    "for i in range (0,len(fake_user_negative)):\n",
    "    for j in range (0,len(fake_business_negative)):\n",
    "        for k in range (0,len(fake_date_negative)):\n",
    "            fake_review.append([fake_user_negative[i],fake_business_negative[j],fake_date_negative[k],np.random.permutation([1,2])[0]])\n",
    "\n",
    "a = np.array(fake_review)\n",
    "fake_review = list(a[np.random.permutation(a.shape[0])[:int(a.shape[0]*0.7)]])\n",
    "            \n",
    "all_review = real_review + fake_review\n",
    "\n",
    "with open('yelp_reviews_with_fake_4.txt','a') as f:\n",
    "    for i in range (0, len(all_review)):\n",
    "        f.write(str(all_review[i][0]) + ',' + str(all_review[i][1]) + ',' + str(all_review[i][2]) + ',' + str(all_review[i][3]) + ',' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 4 Fake Review Result:\n",
    "<img src=\"04.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "In total, based on the results we got above, we can make a conclusion that both D-Cube and M-Zoom work perfectly on detecting injective data. In terms of speed, D-Cube is much faster than traditional M-Zoom algorithm. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
